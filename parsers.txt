# pre_processing\parsing\geometry_parser.py

import numpy as np
import logging
import re
import os

logging.basicConfig(level=logging.WARNING)
#logging.basicConfig(level=logging.INFO)
#logging.basicConfig(level=logging.DEBUG)


def parse_geometry(file_path):
    """
    Parses beam geometry and cross-sectional properties from a structured text file.
    Extracts properties from `[geometry]` and `[section_geometry]` sections.

    The function returns a NumPy array of shape `(1, 20)`, where missing values are set to NaN.

    ============================= 
    Geometry Properties Mapping
    =============================

    Index   Property                            Symbol     Units  
    ----------------------------------------------------------------
    0       Beam Length                         [L]        [m]     
    1       Cross-sectional Area                [A]        [m²]    
    2       Moment of Inertia (x-axis)          [I_x]       [m⁴]    
    3       Moment of Inertia (y-axis)          [I_y]       [m⁴]    
    4       Moment of Inertia (z-axis)          [I_z]       [m⁴]    
    5       Polar Moment of Inertia             [J]        [m⁴]    
    6       Torsional Constant                  [J_t]      [-]
    7       Warping Moment of Inertia           [I_w]      [m⁶]
    8       Centroid (x-position)               [c_x]      [m]     
    9       Centroid (y-position)               [c_y]      [m]     
    10      Centroid (z-position)               [c_z]      [m]     
    11      Static Moment (x-axis)              [s_x]      [m³]    
    12      Static Moment (y-axis)              [s_y]      [m³]    
    13      Static Moment (z-axis)              [s_z]      [m³]    
    14      Radius of Gyration (x-axis)         [r_x]      [m]     
    15      Radius of Gyration (y-axis)         [r_y]      [m]     
    16      Radius of Gyration (z-axis)         [r_z]      [m]
    17      Position of Shear Center (x-axis)   [x_s]      [m]          
    18      Position of Shear Center (y-axis)   [y_s]      [m]
    19      Position of Shear Center (z-axis)   [z_s]      [m]

    Only values within the `[Geometry]` and `[Section_Geometry]` sections are processed.
    Empty lines and comments (`#`) are ignored.

    Parameters
    ----------
    file_path : str
        Path to the geometry properties file.

    Returns
    -------
    numpy.ndarray
        A NumPy array of shape `(1,20)`, where missing values are assigned `NaN`.

    Raises
    ------
    ValueError
        If a geometry property cannot be converted to a float.

    Warnings
    --------
    Logs a warning if an invalid geometry property is encountered.

    Data Fetching
    -----------------------------
    The returned `geometry_array` supports various NumPy indexing techniques:

    Technique           Command                               Description                                  
    ---------------------------------------------------------------------------------------
    Basic Indexing      `geometry_array[0, 0]`                Fetches `L`                     
    Slicing             `geometry_array[0, :5]`               Fetches `[L, A, Ix, Iy, Iz]`               
    Fancy Indexing      `geometry_array[0, [8, 11, 17]]`      Fetches `[c_x, s_x, x_s]`                    

    Example:
    >>> geometry_data = parse_geometry("geometry.txt")
    >>> print(geometry_data)
    array([[8.0, 0.05, 1.3e-4, 2.4e-4, 3.5e-4, 5.1e-5, 4.1e-5, 2.2e-6,
            0.1, 0.2, 0.0, 0.15, 0.25, 0.35, 0.05, 0.07, 0.09, 0.12, 0.18, 0.0]])

    Notes
    -----
    - Properties are formatted as `[Key] Value`, with keys enclosed in square brackets.
    - If a property is missing, `NaN` is assigned at the corresponding index.
    - Inline comments (after `#`) are ignored.
    """

    if not os.path.exists(file_path):
        logging.error(f"[Geometry] File not found: {file_path}")
        raise FileNotFoundError(f"{file_path} not found")

    geometry_array = np.full((1, 20), np.nan)

    geometry_keys = [
        "L", "A", "I_x", "I_y", "I_z", "J", "J_t", "I_w",
        "c_x", "c_y", "c_z", "s_x", "s_y", "s_z",
        "r_x", "r_y", "r_z", "x_s", "y_s", "z_s"
    ]
    geometry_map = {key: i for i, key in enumerate(geometry_keys)}

    relevant_sections = re.compile(r"^\[(geometry|section_geometry)\]$", re.IGNORECASE)
    key_pattern = re.compile(r"^\s*\[(\w+)]\s*(.*)")  # Allow extra spaces

    current_section = None
    found_geometry_section = False

    with open(file_path, 'r') as f:
        for line_number, raw_line in enumerate(f, 1):
            line = raw_line.split("#")[0].strip()  # Remove inline comments

            if not line:
                continue  # Skip empty lines

            # Detect section headers
            if relevant_sections.match(line):
                current_section = "geometry"
                found_geometry_section = True
                continue

            if current_section != "geometry":
                continue  # Ignore other sections

            # Parse `[Key] Value` pairs
            match = key_pattern.match(line)
            if match:
                key, value = match.groups()
                key = key.strip()

                if key in geometry_map:
                    try:
                        geometry_array[0, geometry_map[key]] = float(value.strip())
                    except ValueError:
                        logging.warning(f"[Geometry] Invalid float value at line {line_number}: {value.strip()}")

    if not found_geometry_section:
        logging.warning(f"[Geometry] No valid `[Geometry]` section found in '{file_path}'. Returning NaN-filled array.")

    logging.info(f"[Geometry] Parsed data from '{file_path}':\n{geometry_array}")

    return geometry_array

# pre_processing\parsing\load_parser.py

import numpy as np
import logging
import re
import os

# Set up logging for debugging
logging.basicConfig(level=logging.WARNING)
#logging.basicConfig(level=logging.INFO)
#logging.basicConfig(level=logging.DEBUG)

def parse_load(file_path):
    """
    Parses point load vectors from a structured text file and returns a 2D NumPy array.

    =============================
    Load Properties Mapping
    =============================

    Index   Property    Symbol     Units
    --------------------------------------
    0       X-Position  [x]        [m]
    1       Y-Position  [y]        [m]
    2       Z-Position  [z]        [m]
    3       Force X     [F_x]      [N]
    4       Force Y     [F_y]      [N]
    5       Force Z     [F_z]      [N]
    6       Moment X    [M_x]      [N·m]
    7       Moment Y    [M_y]      [N·m]
    8       Moment Z    [M_z]      [N·m]

    Only numerical values within the `[Loads]` section are processed. Empty lines 
    and comments (`#`) are ignored. Malformed rows are skipped with a warning.

    Parameters
    ----------
    file_path : str
        Path to the load input file.

    Returns
    -------
    numpy.ndarray
        A NumPy array of shape `(N, 9)`, where `N` is the number of valid point loads.
        Each row represents a point load with `[x, y, z, F_x, F_y, F_z, M_x, M_y, M_z]`.

    Raises
    ------
    ValueError
        If a load property cannot be converted to a float.

    Warnings
    --------
    Logs a warning if an invalid load property is encountered.
    """

    # Step 1: Check if the file exists
    if not os.path.exists(file_path):
        logging.error(f"[Load] File not found: {file_path}")
        raise FileNotFoundError(f"{file_path} not found")

    loads_list = []
    header_pattern = re.compile(r"^\[loads\]$", re.IGNORECASE)  # Matches ONLY [Loads]
    current_section = None
    first_numeric_line_detected = False  # Track if header is skipped

    # Step 2: Read and process file
    with open(file_path, 'r') as f:
        for line_number, raw_line in enumerate(f, 1):
            line = raw_line.split("#")[0].strip()  # Remove inline comments

            if not line:
                continue  # Skip empty lines

            # Detect the `[Loads]` section
            if header_pattern.match(line):
                logging.info(f"[Load] Found [Loads] section at line {line_number}. Beginning to parse loads.")
                current_section = "loads"
                continue

            # Skip any data before [Loads] section
            if current_section != "loads":
                continue  

            # Step 3: Process valid data lines
            parts = line.split()

            # Skip header row if it contains non-numeric values
            if not first_numeric_line_detected:
                if not all(re.match(r"^-?\d+(\.\d+)?$", p) for p in parts):
                    logging.warning(f"[Load] Skipping non-numeric header row at line {line_number}: {parts}")
                    continue  # Skip header
                first_numeric_line_detected = True  # Set flag after skipping

            if len(parts) != 9:
                logging.warning(f"[Load] Line {line_number}: Expected 9 values, found {len(parts)}. Content: {parts}. Skipping.")
                continue

            try:
                loads_list.append([float(x) for x in parts])
            except ValueError as e:
                logging.warning(f"[Load] Line {line_number}: Invalid numeric data '{parts}'. Error: {e}. Skipping.")

    # Step 4: Handle case where no valid loads were found
    if not loads_list:
        logging.error(f"[Load] No valid load data found in '{file_path}'. Returning empty array.")
        return np.empty((0, 9), dtype=float)

    # Step 5: Convert to NumPy array and log results
    loads_array = np.array(loads_list, dtype=float)
    logging.info(f"[Load] Parsed {loads_array.shape[0]} load entries from '{file_path}'.")
    logging.debug(f"[Load] Final parsed array:\n{loads_array}")

    return loads_array

# pre_processing\parsing\materials_parser.py

import numpy as np
import logging
import re
import os

logging.basicConfig(level=logging.WARNING)
#logging.basicConfig(level=logging.INFO)
#logging.basicConfig(level=logging.DEBUG)


def parse_material(file_path):
    """
    Parses material properties from a structured text file and returns them as a NumPy array.

    =============================
    Material Properties Mapping
    =============================

    Index   Property                            Symbol     Units
    --------------------------------------------------------------
    0       Young’s Modulus                     [E]        [Pa]     
    1       Shear Modulus                       [G]        [Pa]     
    2       Poisson’s Ratio                     [nu]       [-]      
    3       Density                             [rho]      [kg/m³]  

    Only values within the `[Material]` section are processed. The function skips empty lines 
    and comments (`#`) while parsing. Missing values are replaced with `NaN`.

    Parameters
    ----------
    file_path : str
        Path to the material properties file.

    Returns
    -------
    numpy.ndarray
        A NumPy array of shape `(1, 4)`, containing material properties `[E, G, nu, rho]`. 
        Missing properties are set to `NaN`.

    Raises
    ------
    ValueError
        If a property cannot be converted to a float.

    Warnings
    --------
    Logs a warning if an invalid material property is encountered.
    """

    # Step 1: Check if the file exists
    if not os.path.exists(file_path):
        logging.error(f"[Material] File not found: {file_path}")
        raise FileNotFoundError(f"{file_path} not found")

    # Step 2: Initialize material array with NaN
    material_array = np.full((1, 4), np.nan)

    # Define material properties mapping
    material_keys = ["E", "G", "nu", "rho"]
    material_map = {key: idx for idx, key in enumerate(material_keys)}

    current_section = None
    key_pattern = re.compile(r"\[(.*?)\]\s*(.*)")  # Match `[Key] Value` format
    found_material_section = False

    # Step 3: Read and process file
    with open(file_path, 'r') as f:
        for line_number, raw_line in enumerate(f, 1):
            line = raw_line.split("#")[0].strip()  # Remove inline comments

            logging.debug(f"[Material] Processing line {line_number}: '{line}'")

            if not line:
                logging.debug(f"[Material] Line {line_number} is empty. Skipping.")
                continue  # Skip empty lines

            # Detect the `[Material]` section
            if line.lower() == "[material]":
                logging.info(f"[Material] Found [Material] section at line {line_number}.")
                current_section = "material"
                found_material_section = True
                continue

            if current_section != "material":
                logging.warning(f"[Material] Line {line_number} ignored: Outside [Material] section.")
                continue  

            # Step 4: Process `[Key] Value` pairs
            match = key_pattern.match(line)
            if match:
                key, value = match.groups()
                key = key.strip()

                if key in material_map:
                    try:
                        material_array[0, material_map[key]] = float(value.strip())
                        logging.debug(f"[Material] Parsed: {key} -> {value.strip()}")
                    except ValueError:
                        logging.warning(f"[Material] Line {line_number}: Invalid float value for {key}. Skipping.")

    # Step 5: Handle missing `[Material]` section
    if not found_material_section:
        logging.warning(f"[Material] No valid `[Material]` section found in '{file_path}'. Returning NaN-filled array.")

    logging.info(f"[Material] Parsed data from '{file_path}':\n{material_array}")

    return material_array

# pre_processing\parsing\mesh_parser.py

import ast
import logging
import numpy as np
import re
import os

logging.basicConfig(level=logging.WARNING)
#logging.basicConfig(level=logging.INFO)
#logging.basicConfig(level=logging.DEBUG)

def parse_mesh(mesh_file_path):
    """
    Parses a structured mesh file and computes element lengths using node coordinates.

    =============================
    Mesh Properties Mapping
    =============================

    Index   Property             Key in Dictionary         Data Type             Shape     Units  
    ------------------------------------------------------------------------------------------------
    0       Element Types        `element_types`          `np.ndarray[str]`      (N,)       -      
    1       Node IDs             `node_ids`               `np.ndarray[int]`      (N,)       -      
    2       Node Positions       `node_coordinates`       `np.ndarray[float]`    (N, 3)     [m] 
    3       Connectivity         `connectivity`           `np.ndarray[int]`      (M, 2)     -      
    4       Element Lengths      `element_lengths`        `np.ndarray[float]`    (M,)       [m] 
    5       Element IDs          `element_ids`            `np.ndarray[int]`      (M,)       -      
        

    The function reads mesh data, extracts node positions, and computes 
    element lengths using the Euclidean distance formula. Empty lines and 
    comments (#) are ignored.

    Parameters
    ----------
    mesh_file_path : str
        Path to the structured mesh file.

    Returns
    -------
    dict
        Dictionary "mesh_dictionary" with the following keys:
            - 'element_types': np.ndarray[str]
            - 'node_ids': np.ndarray[int]
            - 'node_coordinates': np.ndarray[float]
            - 'connectivity': np.ndarray[int]
            - 'element_lengths': np.ndarray[float]
            - 'element_ids': np.ndarray[int]  # Included in Returns

    Raises
    ------
    FileNotFoundError
        If the mesh file does not exist.
    ValueError
        If node coordinates or connectivity data cannot be parsed.

    Warnings
    --------
    Logs a warning if an invalid node or connectivity entry is encountered.

    Example
    -------
    >>> mesh_dictionary = parse_mesh("mesh.txt")
    >>> print(mesh_dictionary['element_ids'])
    array([1, 2, 3, ...])

    Notes
    -----
    - Nodes must be formatted as `ID X Y Z (Node1, Node2)`, where connectivity is optional.
    - If connectivity is missing, `-` is used as a placeholder.
    - Inline comments (#) are ignored.
    """

    # 1. Ensure the file exists
    if not os.path.exists(mesh_file_path):
        logging.error(f"[Mesh] File not found: {mesh_file_path}")
        raise FileNotFoundError(f"{mesh_file_path} not found")

    # 2. Prepare storage and regex
    element_types = []
    node_ids = []
    node_coordinates = []
    connectivity_list = []

    # Regex to strictly match lines with only [Mesh] or [Element_Types]
    header_mesh_pattern = re.compile(r"^\[mesh\]$", re.IGNORECASE)
    header_element_types_pattern = re.compile(r"^\[element_types\]$", re.IGNORECASE)

    current_section = None
    found_mesh_section = False
    found_element_types_section = False

    # 3. Read file line-by-line
    with open(mesh_file_path, 'r') as f:
        for line_number, raw_line in enumerate(f, 1):
            # Strip out inline comments (#...) and trailing/leading whitespace
            line = raw_line.split("#")[0].strip()

            logging.debug(f"[Mesh] Processing line {line_number}: '{raw_line.strip()}'")

            # Skip completely empty lines
            if not line:
                logging.debug(f"[Mesh] Line {line_number} is empty. Skipping.")
                continue

            # --- Section detection -----------------------------------------
            if header_element_types_pattern.match(line):
                logging.info(f"[Mesh] Found [Element_Types] at line {line_number}.")
                current_section = "element_types"
                found_element_types_section = True
                continue

            if header_mesh_pattern.match(line):
                logging.info(f"[Mesh] Found [Mesh] at line {line_number}. Parsing mesh data.")
                current_section = "mesh"
                found_mesh_section = True
                continue

            # --- Element_Types section -------------------------------------
            if current_section == "element_types":
                element_types.append(line)
                logging.debug(f"[Mesh] Parsed element type: {line}")
                continue

            # --- Mesh section ----------------------------------------------
            if current_section == "mesh":
                # If line includes 'node_ids', 'x', 'y', 'z' (a column header), skip it
                headers = ["node_ids", "x", "y", "z"]
                if all(header in line.lower() for header in headers):
                    logging.debug(f"[Mesh] Skipping column header at line {line_number}.")
                    continue

                # Expect exactly 5 tokens for a valid node line:
                # node_id, x, y, z, connectivity
                parts = line.split(maxsplit=4)
                if len(parts) < 5:
                    logging.warning(f"[Mesh] Line {line_number}: Incomplete node data. Skipping.")
                    continue

                try:
                    node_id = int(parts[0])
                    x, y, z = map(float, parts[1:4])
                    conn_str = parts[4].strip()

                    node_ids.append(node_id)
                    node_coordinates.append((x, y, z))
                    logging.debug(f"[Mesh] Parsed node {node_id}: ({x}, {y}, {z})")

                    # If connectivity is not '-', parse the tuple
                    if conn_str != "-":
                        try:
                            c_tuple = ast.literal_eval(conn_str)
                            if (isinstance(c_tuple, tuple) and 
                                len(c_tuple) == 2 and 
                                all(isinstance(i, int) for i in c_tuple)):
                                connectivity_list.append(c_tuple)
                                logging.debug(f"[Mesh] Parsed connectivity: {c_tuple}")
                            else:
                                logging.warning(f"[Mesh] Line {line_number}: Invalid connectivity format: {conn_str}")
                        except (ValueError, SyntaxError) as e:
                            logging.warning(f"[Mesh] Line {line_number}: Connectivity parse error '{conn_str}': {e}")
                except ValueError:
                    logging.warning(f"[Mesh] Line {line_number}: Invalid node data. Skipping.")
                continue

            # If we're here, we're outside [Element_Types] or [Mesh]
            logging.warning(f"[Mesh] Line {line_number} ignored: Outside relevant sections.")
        # end for line_number, raw_line in ...

    # 4. Check if we found the key sections
    if not found_mesh_section:
        logging.warning(f"[Mesh] No [Mesh] section found in '{mesh_file_path}'. Returning empty arrays.")
        mesh_dictionary = {
            'element_types': np.empty((0,), dtype=str),
            'node_ids': np.empty((0,), dtype=int),
            'node_coordinates': np.empty((0, 3), dtype=float),
            'connectivity': np.empty((0, 2), dtype=int),
            'element_lengths': np.empty((0,), dtype=float),
            'element_ids': np.empty((0,), dtype=int)  # Added Empty Array
        }
        return mesh_dictionary

    if not found_element_types_section:
        logging.warning(f"[Mesh] No [Element_Types] section found in '{mesh_file_path}'. Returning empty element types array.")
        element_types_array = np.empty((0,), dtype=str)
    else:
        element_types_array = np.array(element_types, dtype=str)

    if not node_ids:
        logging.error(f"[Mesh] No valid node data found in '{mesh_file_path}'. Returning empty arrays.")
        mesh_dictionary = {
            'element_types': element_types_array,
            'node_ids': np.empty((0,), dtype=int),
            'node_coordinates': np.empty((0, 3), dtype=float),
            'connectivity': np.empty((0, 2), dtype=int),
            'element_lengths': np.empty((0,), dtype=float),
            'element_ids': np.empty((0,), dtype=int)  # Added Empty Array
        }
        return mesh_dictionary

    # 5. Convert data to NumPy arrays
    node_ids_array = np.array(node_ids, dtype=int)
    node_coordinates_array = np.array(node_coordinates, dtype=float)
    connectivity_array = np.array(connectivity_list, dtype=int) if connectivity_list else np.empty((0, 2), dtype=int)

    # 6. Compute element lengths
    element_lengths_array = compute_element_lengths(connectivity_array, node_coordinates_array, node_ids_array)

    # 7. Generate element IDs starting from 1
    element_ids_array = np.arange(1, connectivity_array.shape[0] + 1, dtype=int)  # Updated Line

    # 8. Construct the mesh_dictionary
    mesh_dictionary = {
        'element_types': element_types_array,
        'node_ids': node_ids_array,
        'node_coordinates': node_coordinates_array,
        'connectivity': connectivity_array,
        'element_lengths': element_lengths_array,
        'element_ids': element_ids_array  # Added Key-Value Pair
    }

    # Log final stats
    logging.info(
        f"[Mesh] Parsed {len(element_types_array)} element type(s), "
        f"{len(node_ids_array)} nodes, and {len(connectivity_list)} elements from '{mesh_file_path}'."
    )
    logging.debug(
        f"[Mesh] Final parsed data:\n"
        f"  Element Types:\n{element_types_array}\n"
        f"  Nodes:\n{node_coordinates_array}\n"
        f"  Connectivity:\n{connectivity_array}\n"
        f"  Element Lengths:\n{element_lengths_array}\n"
        f"  Element IDs:\n{element_ids_array}"  # Added Debug Information
    )

    return mesh_dictionary

def compute_element_lengths(connectivity_array, node_coordinates_array, node_ids_array):
    """
    Computes element lengths based on 3D node positions.

    Parameters
    ----------
    connectivity_array : np.ndarray[int]
        NumPy array of shape (M, 2), containing node ID pairs.
    node_coordinates_array : np.ndarray[float]
        NumPy array of shape (N, 3), containing node positions.
    node_ids_array : np.ndarray[int]
        NumPy array of shape (N,), containing node identifiers.

    Returns
    -------
    np.ndarray[float]
        NumPy array of shape (M,), containing computed element lengths.

    Raises
    ------
    ValueError
        If a referenced node ID is not found in node_ids_array.
    """

    if connectivity_array.shape[0] == 0:
        logging.debug("[Mesh] No connectivity data found. Returning empty length array.")
        return np.empty((0,), dtype=float)

    # Sort node IDs so we can index them
    sorted_indices = np.argsort(node_ids_array)
    sorted_node_ids = node_ids_array[sorted_indices]

    # Map the connectivity node IDs to their sorted indices
    node_indices = np.searchsorted(sorted_node_ids, connectivity_array)

    # Check for invalid node indices
    invalid_mask = (node_indices[:, 0] >= len(sorted_node_ids)) | (node_indices[:, 1] >= len(sorted_node_ids))
    if np.any(invalid_mask):
        invalid_pairs = connectivity_array[invalid_mask]
        raise ValueError(f"Referenced node IDs not found: {invalid_pairs}")

    # Retrieve the node coordinates
    coord1 = node_coordinates_array[sorted_indices[node_indices[:, 0]]]
    coord2 = node_coordinates_array[sorted_indices[node_indices[:, 1]]]

    # Compute Euclidean distances
    element_lengths_array = np.linalg.norm(coord2 - coord1, axis=1)
    logging.debug(f"[Mesh] Computed element lengths: {element_lengths_array}")

    return element_lengths_array

# pre_processing\parsing\solver_parser.py

import os
import logging
import numpy as np
import re

# Define all valid solver types
VALID_SOLVERS = np.array(["Static", "Dynamic", "Modal"], dtype=str)

def get_solver_registry():
    """
    Returns a registry of SciPy solvers available for solving linear systems.

    Returns:
        dict: Mapping solver names (str) to functions.
    """
    from scipy.sparse.linalg import cg, gmres, minres, bicg, bicgstab, lsmr, lsqr, spsolve
    from scipy.linalg import solve, lu_factor, lu_solve

    return {
        "direct_solver_dense": solve,
        "lu_decomposition_solver": lambda A, b: lu_solve(lu_factor(A), b),
        "direct_solver_sparse": spsolve,
        "conjugate_gradient_solver": cg,
        "generalized_minimal_residual_solver": gmres,
        "minimum_residual_solver": minres,
        "bi-conjugate_gradient_solver": bicg,
        "bi-conjugate_gradient_stabilized_solver": bicgstab,
        "least_squares_solver": lsmr,
        "sparse_least_squares_solver": lsqr,
    }

def parse_solver(file_path):
    """
    Parses solver configuration from a structured text file and validates against the solver registry.

    =============================
    Solver Properties Mapping
    =============================

    Index   Solver Type    Status         Description
    -------------------------------------------------------------
    0       Static        Solver Name    Direct solver for static problems
    1       Dynamic       Solver Name    Time-dependent solver
    2       Modal         Solver Name    Solver for eigenvalue problems

    The function reads a solver configuration file and checks if the specified solver names exist 
    in the solver registry. If a solver is not found, it is marked as `"Off"`.

    Parameters
    ----------
    file_path : str
        Path to the solver configuration file.

    Returns
    -------
    np.ndarray[str]
        A NumPy array of shape `(3,)`, containing solver names for `["Static", "Dynamic", "Modal"]`.
        If a solver is missing or unrecognized, `"Off"` is assigned.

    Raises
    ------
    ValueError
        If an invalid solver type is encountered.

    Warnings
    --------
    Logs a warning if a solver is unrecognized or missing.

    Data Fetching
    -------------
    The returned `solver_array` supports standard NumPy indexing techniques:

    Technique                Command                        Description
    -------------------------------------------------------------------
    Fetch solver for Static  `solver_array[0]`             Returns solver name for Static
    Fetch all solvers        `solver_array[:]`             Returns all solver names

    Example
    -------
    >>> solver_array = parse_solver("solver_config.txt")
    >>> print(solver_array)
    array(['Direct Solver', 'Off', 'Eigen Solver'], dtype='<U20')

    Notes
    -----
    - Solvers must be formatted as `SolverType SolverName` in the configuration file.
    - If no solver name is specified for a type, it is marked as `"Off"`.
    - Inline comments (`#`) are ignored.
    """

    # Load available solvers from the registry
    solver_registry = get_solver_registry()

    # Initialize all solver types to "Off" by default with increased string length
    solver_array = np.full((3,), "Off", dtype='<U30')  # Increased from '<U20' to '<U30'

    # Regex to detect the `[Solver]` section (case-insensitive)
    header_pattern = re.compile(r"\[.*?solver.*?\]", re.IGNORECASE)

    current_section = None

    if not os.path.exists(file_path):
        logging.error(f"Solver configuration file not found: {file_path}")
        raise FileNotFoundError(f"{file_path} not found")

    with open(file_path, 'r') as f:
        for line_number, raw_line in enumerate(f, 1):
            # Strip inline comments ('#') and whitespace
            line = raw_line.split("#")[0].strip()
            if not line:
                continue  # Skip empty lines

            # Detect [Solver] section
            if header_pattern.match(line):
                current_section = "solver"
                continue

            # If not in [Solver] section yet, ignore
            if current_section != "solver":
                continue

            # Parse each solver line: "Static SolverName", etc.
            parts = line.split()
            if len(parts) < 1:
                logging.warning(f"[Solver] Line {line_number}: Missing solver type.")
                continue

            solver_type = parts[0].strip()
            # Find which valid solver index this corresponds to
            idx = np.where(VALID_SOLVERS == solver_type)[0]
            if len(idx) == 0:
                logging.error(f"[Solver] Line {line_number}: Invalid solver type '{solver_type}'. "
                              f"Expected one of {VALID_SOLVERS.tolist()}.")
                raise ValueError(f"Invalid solver type: {solver_type}")

            # If there's a solver name, it will be the rest of the tokens
            solver_name = " ".join(parts[1:]) if len(parts) > 1 else None

            if not solver_name:
                # No solver name provided
                logging.info(f"[Solver] Line {line_number}: '{solver_type}' has no solver name. Marking as 'Off'.")
                continue

            # Validate solver_name against the registry
            if solver_name in solver_registry:
                solver_array[idx[0]] = solver_name
            else:
                logging.warning(f"[Solver] Line {line_number}: Unrecognized solver name '{solver_name}' for '{solver_type}'. "
                                "Setting to 'Off' (default).")

    return solver_array
